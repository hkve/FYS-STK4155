Discussion here, in present/past tense.

\subsection{Interpretation of LWTA Networks}
    \comment{\Anna or \Carl}


\subsection{Link to existing research}
    \comment{I write about the CIFAR-10 results here, but will probably make a more appropriate section. -\Carl} \\
    The results we got on the CIFAR-10 dataset, with the best test accuracy of 51.28\%, was not particularly impressive. It is however known to be a difficult dataset to score well on, with the state-of-the-art convolutional maxout network achieving a test accuracy 88.32\% \citep{Maxout_Networks}. This was done with a significantly larger network, with convolutional layers, and with more thorough image pre-processing. Channel-out networks have not achieved the same level of accuracy, with a top score of 86.80\% test accuracy \citep{Wang}. This was also our conclusion, with the channel-out network slightly underperforming maxout. However, both channel-out and maxout networks bettered the ordinary ReLU network result by 1.50\% and 2.09\% respectively.

    \comment{Maybe include discussion on ML as a tool in neurobiological research \Anna} 


\subsection{Overfitting}
    \comment{I thought it would be fitting (haha) with a separate discussion on overfitting and the various ways in which we have combatted it here. -\Carl}


\subsubsection{Hyperparameter Tuning}
    Our motivation was not to explore all of the hyperparameter space, but rather explore some structures in the high performing models. (eg. structures: MO vs CO vs Dense, and how many layer)
    \comment{\Carl or \Anna} \\
    \comment{On CIFAR-10: $27+12+6+4 = 49$} \\
    \comment{On EPL: $3 \times (81 + 34 + 15 + 8 + 5) = 3 \times 143 = 429$}

\subsubsection{PCA - did not choose the PCA-features}

\subsubsection{Explainability of MO/CO}
    \comment{Can features be recognised in the pathways? NB! Features human notice are not necessarily the same as the ones a machine notice -\Anna}