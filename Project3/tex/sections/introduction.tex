The root inspiration of neural networks was trying to mimic the way biological systems encode and process sensory information. As the field of neuroscience has advanced it has again become source of inspiration for improving upon the existing neural network (NN) frameworks. In this project, we want to explore the biological phenomenon of local competition among neurons to encode information by looking at \textit{local winner-takes-all} (LWTA) algorithms for neural networks. We go on to present two algorithms for LWTA networks: \textit{Maxout} networks and \text{channel-out} networks. The former implements the idea of local competition between neurons, and the latter build on the idea of encoding information on neural pathways between the layers.

Winner-takes-all behaviour is well documented in visual perception, and as such it would be natural to try our algorithms against image recognition datasets. Thus, we apply our networks to the benchmark MNIST and CIFAR-10 datasets. In doing so, we aim to explore the architecture of LWTA NN and how information is encoded.

Additionally, we wanted to build our own dataset, both for analysis and for applying LWTA NNs. Inspired by current events, we build a dataset based on statistics from the 2019/2020 Premier League football season, seeing whether neural networks can use data from previous games and seasons to predict the outcome of individual matches.
