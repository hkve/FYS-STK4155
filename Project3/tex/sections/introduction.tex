The root inspiration of neural networks was trying to mimic the way biological systems encode and process sensory information. As the field of neuroscience has advanced it has again become source of inspiration for improving upon the existing neural network (NN) frameworks. In this project, we want to explore the biological phenomenon of local competition among neurons to encode information of neural pathways by looking at \textit{local winner-takes-all} (LWTA) algorithms for neural networks. We go on to present two algorithms for LWTA networks, \textit{maxout} networks and \text{channel-out} networks. The former implements the idea of local competition between neurons, and the latter build on the idea of encoding information on neural pathways between the layers.

Winner-takes-all behaviour is well documented in visual perception, and as such it would be natural to try our algorithms against image recognition datasets. Thus, we apply our networks to the benchmark MNIST and CIFAR-10 datasets. In doing so, we aim to explore the architecture of LWTA NN and how information is encoded.

Additionally, we wanted to 
