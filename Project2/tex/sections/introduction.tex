

Neural Networks (NNs) have taken the world of regression by storm, and have already been applied to an incredibly rich plethora of different problems. Here we will introduce one of the simpler, yet effective NN frameworks with a number of fully connected hidden layers. Before we introduce our NN framework, we will take a dive into gradient descent (GD) methods, as these are the industry standard for optimising NNs when training them. We will apply ten different GD methods and compare the performance in optimising OLS and ridge cost functions. Building on our earlier project~\citep{Project1}, we will then train and apply our NNs on two-dimensional Nicaraguan terrain, and compare performance with linear regression methods.

Another area where NNs have proved effective has been in classification problems, as is common in medicine for instance. We will introduce and employ standard logistic regression and our NN on breast cancer data, a binary classification problem where we classify tumours either as malignant or benign.

We will compare our implementations with those of a standard library; \verb|scikit-learn|.
