We have introduced and implemented a wide range of GD and SGD algorithms, and found that they perform satisfactorily when minimising OLS and ridge cost functions of either linear models, logistic models or neural networks with up to many thousands of parameters. Minimisation of linear models was done on the Franke function data with stochastic noise, using a polynomial expansion of degree 5 of the two arguments. Fitting to 600 points split into train- and test portions with a $\sfrac{3}{4}$ split, we found that adding momentum to the GD algorithm increased convergence rate and decreased sensitivity to initialisation, but decreased stability. Adding stochasticity did much the same, but using tunable learning rates as with the AdaGrad, RMSprop and Adam algorithms increased stability. Overall, the momentum based SGD with Adam performed the best with a validation MSE of $0.1660 \pm 0.0018$ using the OLS cost function with 500 epochs and a batch size of 200.

This led us to employ the Adama SGD when training our NNs both for regression of Nicaraguan terrain data similar to the Franke data, and classification of breast tumours from the Wisconsin breast cancer dataset. In the regression case, we compared our results with those found from linear regression based on methods from \cite{Project1}, expanding the two arguments of the terrain data polynomially to degree 11 and analytically finding the optimum parameters with an OLS cost function. Using a NN with 5 hidden layers with 200 nodes each, and training on 450 of the total 600 data points with 500 epochs of SGD with Adam and a batch size of 200, we got a validation MSE of $0.078$ compared with $0.171$ from the linear model. With a network of this size, we found that adding a penalisation on the size of the weights to improve the results, using an $L_2$ ridge penalisation parameter $\lambda = 10^{-4}$. This result was the best performed best among the various network architectures we tried out, all of which were smaller networks. In the future, it would be interesting to take a deeper dive into how the architectures are best trained by looking more closely at different numbers of epochs and batch sizes used with our SGD methods.

We tried using different activation functions for the hidden layers of our network, both for regression and classification, and found that the sigmoid activation function gave us the best results in both cases, with the ReLU functions close behind for regression and $\tanh$ for classification. \comment{Is this right???}

The Wisconsin Breast Cancer dataset was found to be quite conducive to creating good models, and as such logistic regression and small NNs both produced excellent validation accuracies, even with relatively little training or hyperparameter tuning. Notably, learning rate required very little tuning. The highest validation accuracy (0.993) was achieved with a shallow NN with just one hidden layer with 5 nodes, with a penalisation on the weights of $\lambda=10^{-3.5}$, but we argue that with more training, either logistic regression or NN could probably achieve a full accuracy of 1. In the future, it would be interesting to explore a smaller train-test split of the data, seeing whether we could predict more unseen data with less training data, or do a feature selection analysis to find which features were more important in classifying the tumours.