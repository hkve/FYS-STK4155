@misc{Dua:2019,
    author = "Dua, Dheeru and Graff, Casey",
    year = "2017",
    title = "{UCI} Machine Learning Repository",
    url = "http://archive.ics.uci.edu/ml",
    institution = "University of California, Irvine, School of Information and Computer Sciences" 
}


@Article{BCE,
AUTHOR = {Ramos, Daniel and Franco-Pedroso, Javier and Lozano-Diez, Alicia and Gonzalez-Rodriguez, Joaquin},
TITLE = {Deconstructing Cross-Entropy for Probabilistic Binary Classifiers},
JOURNAL = {Entropy},
VOLUME = {20},
YEAR = {2018},
NUMBER = {3},
ARTICLE-NUMBER = {208},
URL = {https://www.mdpi.com/1099-4300/20/3/208},
ISSN = {1099-4300},
ABSTRACT = {In this work, we analyze the cross-entropy function, widely used in classifiers both as a performance measure and as an optimization objective. We contextualize cross-entropy in the light of Bayesian decision theory, the formal probabilistic framework for making decisions, and we thoroughly analyze its motivation, meaning and interpretation from an information-theoretical point of view. In this sense, this article presents several contributions: First, we explicitly analyze the contribution to cross-entropy of (i) prior knowledge; and (ii) the value of the features in the form of a likelihood ratio. Second, we introduce a decomposition of cross-entropy into two components: discrimination and calibration. This decomposition enables the measurement of different performance aspects of a classifier in a more precise way; and justifies previously reported strategies to obtain reliable probabilities by means of the calibration of the output of a discriminating classifier. Third, we give different information-theoretical interpretations of cross-entropy, which can be useful in different application scenarios, and which are related to the concept of reference probabilities. Fourth, we present an analysis tool, the Empirical Cross-Entropy (ECE) plot, a compact representation of cross-entropy and its aforementioned decomposition. We show the power of ECE plots, as compared to other classical performance representations, in two diverse experimental examples: a speaker verification system, and a forensic case where some glass findings are present.},
DOI = {10.3390/e20030208}
}

@misc{Project1,
  author          = {Aasen, Anna Hjertvik and Fevang, Carl Martin and Kvernmoen, HÃ¥kon},
  title           = {Bias-Variance Tradeoff in Simple Linear Models},
  url             = {https://github.com/hkve/FYS-STK4155/blob/main/Project1/Project1.pdf},
  year            = {2022}
}

@article{scikit-learn,
 title={Scikit-learn: Machine Learning in {P}ython},
 author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
 journal={Journal of Machine Learning Research},
 volume={12},
 pages={2825--2830},
 year={2011}
}

@unpublished{MortenUAT,
title={Neural networks},
author={Hjorth-Jensen, Morten},
URL={https://compphysics.github.io/MachineLearning/doc/LectureNotes/_build/html/chapter9.html}
}

@article{HornikEtAl89,
  added-at = {2012-08-18T21:01:01.000+0200},
  author = {Hornik, K. and Stinchcombe, M. and White, H.},
  biburl = {https://www.bibsonomy.org/bibtex/2093b3edd165afb94d52365daefa7e4db/dalbem},
  date-added = {2008-03-06 20:17:54 -0300},
  date-modified = {2008-03-06 20:17:54 -0300},
  groups = {public},
  interhash = {9948713640c726f50c4c5a57e121f7ac},
  intrahash = {093b3edd165afb94d52365daefa7e4db},
  journal = {Neural Networks},
  keywords = {},
  number = 5,
  pages = {359-366},
  timestamp = {2012-08-18T21:01:01.000+0200},
  title = {Multilayer feedforward networks are universal approximators},
  username = {dalbem},
  volume = 2,
  year = 1989
}
