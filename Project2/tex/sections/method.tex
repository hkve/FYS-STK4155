\comment{Suggestion: future tense}\\
\subsection{Datasets}
    \comment{Here we write about the datasets we use, as before. Maybe reference project 1 about Franke function?}\\
    \comment{Mention data scaling.}\\

    \subsubsection*{Wisconsin Breast Cancer data set}\label[sec]{breast_cancer_dataset}
    For regression problems, the Wisconsin Breast Cancer data set \cite{Dua:2019} will be used. Tumor features are computed from digitized images, describing characteristics of the cell nuclei present in the image. In total there are $n = 569$ unique instances, where each instance has the respective tumor marked as either malignant (M) or benign (B). We will aim to classify the tumor as M or B based on 10 different attributes ranging from tumor radius to texture. Each of these 10 attributes is again split up into three different measurements, named mean, standard error and worst. The latter describes the mean of the three largest measurements. This data set serves a good real-world benchmarking set, containing not too many instances and no missing fields.  

\subsection{Assessing Gradient Descent}
    \comment{Trying out the gradient descent methods and comparing them.}\\
    \comment{I have imported data and parameters at random by trial. We can discuss the choices later}\\
    Our first analysis will be a comparison of the various GD algorithms, as this will make the basis for our neural network optimisation. We will test it on the Franke function with 600 data points, with a train-test split of $\sfrac{3}{4}$, and a noise term added with std $\sigma=0.1$.

    First we will minimise the OLS cost function
    \begin{align}
        \msub{C}{OLS}(\vec{\theta}) = \frac{1}{n}\sum_{i=1}^n \pclosed{X_{i*}\vec{\theta} - y_i}^2,
    \end{align}
    with a polynomial expansion of degree $5$ of the Franke function arguments $x,y$. 

    \comment{Mention initialising SGDs with same random seed for every learning rate.}

\subsection{Classification problems}
    Thus far, we have only aimed at solving regression problems. The machinery regarding neural networks we have introduced here, can with some modification be used to approach \textit{classification} problems. Instead of predicting targets in a continuous domain ($y_i \in \mathbb{R}$), we aim to put the target $y_i$ in a specific class ($y_i \in \mathcal{Q}$), where $\mathcal{Q}$ is the set of possible outcomes. For comparison purposes, we will also implement a logistic regression method.

    For our case using the Wisconsin Breast data set presented in \cref{breast_cancer_dataset}, we aim to classify either M or B. These categories are mutually exclusive, thus determining M or not M is sufficient (i.e. $\mathcal{Q} = \{ M, \neg M \}$). This leaves us with a binary problem, represented with $y_i \in \{ 1, 0 \}$ where $y_i = 1$ implies M and $y_i = 0$ not M.

    To measure the goodness of fit in for our classification problems, we use the \textit{accuracy} score. This metric simply counts the number correctly classified cases, divided by the total number of cases:

    \begin{align}
        A(y_i, \hat{y}_i) = \frac{1}{n}\sum_{i=1}^{n} I(\hat{y}_i = y_i), \\
        I(\hat{y}_i = y) = \begin{cases}
            1\hspace{10px}&\text{if }\hat{y}_i = y \\
            0\hspace{10px}&\text{else}
        \end{cases} \nonumber
    \end{align}
    Where $I$ is the indicator function. We note that if all cases are classified correctly, the sum will evaluate to $n$ and if all are classified wrongly, it will evaluate to 0. Thus, the accuracy is bounded by $0 \leq A(y_i, \hat{y}_i) \leq 1$.

    \subsubsection*{Logistic Regression}
    To be continued ...

    \subsubsection*{Neural Network approach}
    As a loss function suitable for classification problems, the Binary Cross Entropy (BCE) \cite{BCE} will be used:
    \begin{align}
        \msub{C}{BCE} = -\frac{1}{n}\sum_{i=1}^{n} y_i \log{\hat{p}_i} + (1-y_i) \log{(1-\hat{p}_i)}
        \label{eq:BCE_loss_function}
    \end{align} 
    Where $\hat{p}_i$ is the predicted probability of $y_i = 1$ given $x_i$.  